{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc118d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaz_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ada172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Убираем пустые / None / NaN / слишком короткие строки\n",
    "df_clean = df[df[\"text_original\"].astype(str).str.strip().str.len() > 0].copy()\n",
    "\n",
    "# 2. Убираем дубликаты\n",
    "df_clean = df_clean.drop_duplicates(subset=[\"text_original\"]).reset_index(drop=True)\n",
    "\n",
    "# 3. Сэмплируем 3000 случайных строк\n",
    "golden_df = df_clean.sample(3000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 4. Сохраняем\n",
    "golden_df.to_csv(\"golden_sample_3000.csv\", index=False)\n",
    "golden_df.to_json(\"golden_sample_3000.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "golden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ВАЖНО: перезаписываем системные переменные значениями из .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"repr(api_key):\", repr(api_key))\n",
    "print(\"len(api_key):\", len(api_key) if api_key is not None else None)\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"❌ OPENAI_API_KEY не найден\")\n",
    "elif not api_key.startswith(\"sk-\"):\n",
    "    print(\"❌ Ключ не начинается с 'sk-'\")\n",
    "else:\n",
    "    print(\"✅ Ключ найден, первые 12 символов:\", api_key[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Загружаем .env\n",
    "load_dotenv()\n",
    "\n",
    "# Читаем ключ\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "# === ПАРАМЕТРЫ ===\n",
    "INPUT_CSV = \"golden_sample_3000.csv\"       # входной голденсет\n",
    "OUTPUT_JSONL = \"golden_annotated.jsonl\"    # аннотации построчно\n",
    "OUTPUT_CSV = \"golden_annotated.csv\"        # финальная табличка\n",
    "TEXT_COL = \"text_original\"                 # имя колонки с текстом\n",
    "MODEL_NAME = \"gpt-4.1-mini\"                # или gpt-4.1, gpt-4o-mini и т.п.\n",
    "BATCH_SIZE = 30                            # сколько комментариев отправляем за раз\n",
    "SLEEP_BETWEEN_CALLS = 0.5                  # пауза между запросами, чтобы не заддосить API\n",
    "\n",
    "\n",
    "# === СИСТЕМНЫЙ ПРОМПТ ===\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Сен қазақ тіліндегі пікірлерді модерациялайтын көмекшісің.\n",
    "Саған әр пікір (комментарий) мәтіні беріледі. Сенің міндетің – оны токсиктілік\n",
    "бойынша келесі бинарлық белгілермен белгілеу (true/false).\n",
    "\n",
    "Анықтамалар:\n",
    "- is_toxic: Пікірде кез келген токсиктілік бар ма? Егер төмендегі кез келген\n",
    "  категория true болса, is_toxic = true.\n",
    "- toxic: Жалпы агрессивті, құрметсіз, өшпенді реңк (міндетті түрде балағат сөз\n",
    "  болмауы мүмкін).\n",
    "- obscene: Балағат/боқауыз сөздер, өте дөрекі сленг, әдепсіз сөздер.\n",
    "- threat: Белгілі бір адамға немесе адамдар тобына физикалық зиян келтіремін\n",
    "  деп қорқыту (мысалы, ұрып жіберемін, өлтіремін деген сияқты).\n",
    "- insult: Белгілі бір адамды немесе адамдарды қорлау, кемсіту (ақымақ, мал, т.б.).\n",
    "- hate: Әлеуметтік топқа (ұлт, нәсіл, дін, жыныс, ориентация, т.б.) бағытталған\n",
    "  өшпенділік, кемсіту, адам ретінде құқығын жоққа шығару.\n",
    "\n",
    "Әр пікір үшін:\n",
    "- Әр белгіге true/false бер,\n",
    "- Қысқа explanation (2–3 сөйлемнен аспасын) жазып бер: неге дәл осылай\n",
    "  белгілегеніңді түсіндір. Егер пікір бейтарап (токсикті емес) болса,\n",
    "  оны да жазып жібер (мысалы, \"бейтарап пікір, агрессия жоқ\" деген сияқты).\n",
    "\n",
    "МАҢЫЗДЫ:\n",
    "- Тек JSON қайтар. Басқа ешқандай мәтін жазба.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_user_prompt(items: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    items: список словарей вида {\"id\": ..., \"text\": ...}\n",
    "    Формируем пользовательский промпт с несколькими комментариями.\n",
    "    \"\"\"\n",
    "    lines = [\n",
    "        \"Төменде бірнеше пікір берілген. Әр пікір үшін төмендегі JSON форматында жауап бер:\",\n",
    "        \"\",\n",
    "        \"{\",\n",
    "        '  \"items\": [',\n",
    "        '    {',\n",
    "        '      \"id\": \"<id>\",',\n",
    "        '      \"is_toxic\": true/false,',\n",
    "        '      \"toxic\": true/false,',\n",
    "        '      \"obscene\": true/false,',\n",
    "        '      \"threat\": true/false,',\n",
    "        '      \"insult\": true/false,',\n",
    "        '      \"hate\": true/false,',\n",
    "        '      \"explanation\": \"<қысқа түсіндірме>\"',\n",
    "        '    },',\n",
    "        '    ...',\n",
    "        '  ]',\n",
    "        \"}\",\n",
    "        \"\",\n",
    "        \"Пікірлер тізімі:\"\n",
    "    ]\n",
    "    for it in items:\n",
    "        lines.append(f'ID: {it[\"id\"]}')\n",
    "        # Экранируем переносы строк на всякий случай\n",
    "        text_clean = str(it[\"text\"]).replace(\"\\n\", \" \").strip()\n",
    "        lines.append(f'Text: {text_clean}')\n",
    "        lines.append(\"---\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def annotate_batch(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Делает один запрос к OpenAI для батча комментариев\n",
    "    и возвращает список аннотаций по каждому id.\n",
    "    \"\"\"\n",
    "    user_prompt = build_user_prompt(items)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    # Парсим JSON\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        # Если модель вдруг вернула мусор — можно логировать и/или ретраить\n",
    "        raise RuntimeError(f\"JSON parsing error. Raw content:\\n{content}\")\n",
    "\n",
    "    if \"items\" not in data or not isinstance(data[\"items\"], list):\n",
    "        raise RuntimeError(f\"Unexpected JSON structure: {data}\")\n",
    "\n",
    "    return data[\"items\"]\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "    # Готовим список элементов для аннотации\n",
    "    records = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[TEXT_COL]\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            continue\n",
    "        records.append({\n",
    "            \"id\": int(idx),   # можно заменить на row[\"id\"], если у тебя есть явный id\n",
    "            \"text\": text.strip(),\n",
    "        })\n",
    "\n",
    "    print(f\"Всего комментариев для разметки: {len(records)}\")\n",
    "\n",
    "    # Проходимся по батчам и пишем результат в JSONL\n",
    "    annotated = []\n",
    "    with open(OUTPUT_JSONL, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for i in range(0, len(records), BATCH_SIZE):\n",
    "            batch = records[i:i + BATCH_SIZE]\n",
    "            print(f\"Обрабатываем батч {i}–{i+len(batch)-1}...\")\n",
    "\n",
    "            try:\n",
    "                batch_labels = annotate_batch(batch)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при аннотации батча {i}: {e}\")\n",
    "                # Можно сделать ретрай, паузу и т.д.\n",
    "                continue\n",
    "\n",
    "            # Сохраняем в JSONL по одной строке\n",
    "            for item in batch_labels:\n",
    "                f_out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "                annotated.append(item)\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    print(f\"Всего размечено: {len(annotated)}\")\n",
    "\n",
    "    # Собираем всё в DataFrame и мёрджим с исходным golden_df\n",
    "    ann_df = pd.DataFrame(annotated)\n",
    "\n",
    "    # Приводим логические поля к bool\n",
    "    bool_cols = [\"is_toxic\", \"toxic\", \"obscene\", \"threat\", \"insult\", \"hate\"]\n",
    "    for col in bool_cols:\n",
    "        if col in ann_df.columns:\n",
    "            ann_df[col] = ann_df[col].astype(bool)\n",
    "\n",
    "    # Соединяем по id\n",
    "    df_golden = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "    merged = df_golden.merge(ann_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "    merged.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Аннотированный голденсет сохранён в {OUTPUT_CSV}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. Оригинальный golden set\n",
    "df_golden = pd.read_csv(\"golden_sample_3000.csv\")\n",
    "df_golden = df_golden.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "# 2. Загрузка аннотаций (если ты их сохранял в JSONL по одной строке)\n",
    "ann_df = pd.read_json(\"golden_annotated.jsonl\", lines=True)\n",
    "\n",
    "# 3. Приводим типы id к строке с обеих сторон\n",
    "df_golden[\"id\"] = df_golden[\"id\"].astype(str)\n",
    "ann_df[\"id\"] = ann_df[\"id\"].astype(str)\n",
    "\n",
    "# 4. Мёрджим\n",
    "merged = df_golden.merge(ann_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "print(len(df_golden), len(ann_df), len(merged))\n",
    "merged.to_csv(\"golden_annotated_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac159eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6565386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccbb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged = pd.read_csv(\"golden_annotated_merged.csv\")\n",
    "df = pd.read_csv('kaz_df.csv')\n",
    "df = df[~df.comment_id.isin(merged.comment_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_KZ_CHECKPOINT = \"./kaz_roberta_toxic_kz\"  # <-- твой путь\n",
    "\n",
    "tokenizer_kz = AutoTokenizer.from_pretrained(MODEL_KZ_CHECKPOINT)\n",
    "model_kz = AutoModelForSequenceClassification.from_pretrained(MODEL_KZ_CHECKPOINT)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_kz.to(device)\n",
    "model_kz.eval()\n",
    "\n",
    "# ПОРЯДОК ЛЕЙБЛОВ ДОЛЖЕН СОВПАДАТЬ С ТЕМ, КАК ТЫ УЧИЛ МОДЕЛЬ\n",
    "tox_aspect_names_kz = [\"toxic\", \"obscene\", \"threat\", \"insult\", \"hate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ceccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity_batch_kz(texts, aggregate=False):\n",
    "    \"\"\"\n",
    "    texts: список сырых значений (строки, NaN, числа и т.д.)\n",
    "    aggregate=False -> возвращает матрицу [batch, 5] по аспектам\n",
    "    aggregate=True  -> возвращает вектор агрегированного score [batch]\n",
    "                      (вероятность, что текст токсичен по хоть одному аспекту)\n",
    "    \"\"\"\n",
    "    # чистим вход: всё к строке, NaN/None -> \"\"\n",
    "    cleaned_texts = []\n",
    "    for t in texts:\n",
    "        if t is None or (isinstance(t, float) and pd.isna(t)):\n",
    "            cleaned_texts.append(\"\")\n",
    "        else:\n",
    "            cleaned_texts.append(str(t))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer_kz(\n",
    "            cleaned_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "\n",
    "        logits = model_kz(**inputs).logits\n",
    "        proba = torch.sigmoid(logits).cpu().numpy()  # shape: [batch, 5]\n",
    "\n",
    "    if aggregate:\n",
    "        # union probability: 1 - prod(1 - p_i) по всем 5 аспектам\n",
    "        agg = 1.0 - np.prod(1.0 - proba, axis=1)\n",
    "        return agg  # shape: [batch]\n",
    "\n",
    "    return proba  # shape: [batch, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity_batch_kz_compat(texts, aggregate=False):\n",
    "    \"\"\"\n",
    "    Совместимый по форме вариант:\n",
    "    aggregate=True -> 1 - p[:,0] * (1 - p[:,-1])\n",
    "    НО: у тебя p[:,0] = P(toxic), p[:,-1] = P(hate), это НЕ то же самое, что в cointegrated.\n",
    "    \"\"\"\n",
    "    cleaned_texts = []\n",
    "    for t in texts:\n",
    "        if t is None or (isinstance(t, float) and pd.isna(t)):\n",
    "            cleaned_texts.append(\"\")\n",
    "        else:\n",
    "            cleaned_texts.append(str(t))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer_kz(\n",
    "            cleaned_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "\n",
    "        logits = model_kz(**inputs).logits\n",
    "        proba = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    if aggregate:\n",
    "        agg = 1.0 - proba[:, 0] * (1.0 - proba[:, -1])\n",
    "        return agg\n",
    "    return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32edc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_toxicity_to_df_kz(\n",
    "    df,\n",
    "    text_col=\"text_original\",\n",
    "    batch_size=64,\n",
    "    add_aspects=True,\n",
    "    use_compat_formula=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: DataFrame с текстами\n",
    "    text_col: колонка с текстом\n",
    "    batch_size: размер батча\n",
    "    add_aspects: если True — создаст колонки по аспектам\n",
    "    use_compat_formula: если True — использовать старую формулу cointegrated\n",
    "                        (1 - p[:,0] * (1 - p[:,-1]));\n",
    "                        если False — union probability по всем аспектам.\n",
    "    \"\"\"\n",
    "    all_agg_scores = []\n",
    "    all_aspects = []\n",
    "\n",
    "    fn = text2toxicity_batch_kz_compat if use_compat_formula else text2toxicity_batch_kz\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_texts = df[text_col].iloc[i:i + batch_size].tolist()\n",
    "\n",
    "        # всегда берём proba аспектов:\n",
    "        batch_proba = text2toxicity_batch_kz(batch_texts, aggregate=False)  # [B, 5]\n",
    "\n",
    "        # агрегат в зависимости от режима\n",
    "        if use_compat_formula:\n",
    "            batch_agg = 1.0 - batch_proba[:, 0] * (1.0 - batch_proba[:, -1])\n",
    "        else:\n",
    "            batch_agg = 1.0 - np.prod(1.0 - batch_proba, axis=1)\n",
    "\n",
    "        all_agg_scores.extend(batch_agg.tolist())\n",
    "        all_aspects.append(batch_proba)\n",
    "\n",
    "    # агрегированный score\n",
    "    df[\"toxicity_score_kz\"] = all_agg_scores\n",
    "\n",
    "    if add_aspects:\n",
    "        aspects_arr = np.vstack(all_aspects)  # [N, 5]\n",
    "        for j, name in enumerate(tox_aspect_names_kz):\n",
    "            df[f\"tox_kz_{name}\"] = aspects_arr[:, j]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df уже есть, тексты в \"text_original\"\n",
    "df = add_toxicity_to_df_kz(\n",
    "    df,\n",
    "    text_col=\"text_original\",\n",
    "    batch_size=64,\n",
    "    add_aspects=True,\n",
    "    use_compat_formula=False,  # рекомендую False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c950a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('toxicity_score_kz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
