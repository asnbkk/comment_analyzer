{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc118d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbf1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaz_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ada172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_original</th>\n",
       "      <th>lang_model</th>\n",
       "      <th>is_kazakh_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwQ0sI9XYLlZ49FvOl4AaABAg</td>\n",
       "      <td>–ú—ã–Ω–∞ “õ–æ–π–ª–∞—Ä —Å—ñ–≥”ô–ø –±—ñ—Ç—Ç—ñ –º–∞–ª–¥–∞—Ä–¥—ã –∂–∏–Ω–∞–ø –∞–ª“ì–∞–Ω “õ...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgwCm4vOhM7_w3oEhON4AaABAg</td>\n",
       "      <td>–ê–ª–º–∞—Ç—ã –∞–∑–∞–º–∞—Ç—Ç–∞—Ä—ã –∂–∞—Ä–∞–π—Å—ã“£–¥–∞—Ä –∞–ª“ì–∞</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgzmFC00qiAYhuALblJ4AaABAg</td>\n",
       "      <td>“ö–∞–π—Ä–∞—Ç “ö“±–¥–∞–π–±–µ—Ä–≥–µ–Ω–æ–≤ —à—ã“õ—Ç—ã–º–∞?</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgyFDkkHQwCG9iZiriN4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä –º–æ–ª–æ–¥–µ—Ü ,–ø–æ–π–º–∏—Ç–µ –æ–¥–∏–Ω –≤ –ø–æ–ª–µ –Ω–µ –≤–æ–∏–Ω ,“õ...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugwo7_t8DiAVTQ05zQx4AaABAg</td>\n",
       "      <td>”ò–¥–µ–º—ñ —Ä–∏–∑–∞–º—ã–Ω</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   comment_id  \\\n",
       "0  UgwQ0sI9XYLlZ49FvOl4AaABAg   \n",
       "1  UgwCm4vOhM7_w3oEhON4AaABAg   \n",
       "2  UgzmFC00qiAYhuALblJ4AaABAg   \n",
       "3  UgyFDkkHQwCG9iZiriN4AaABAg   \n",
       "4  Ugwo7_t8DiAVTQ05zQx4AaABAg   \n",
       "\n",
       "                                       text_original lang_model  \\\n",
       "0  –ú—ã–Ω–∞ “õ–æ–π–ª–∞—Ä —Å—ñ–≥”ô–ø –±—ñ—Ç—Ç—ñ –º–∞–ª–¥–∞—Ä–¥—ã –∂–∏–Ω–∞–ø –∞–ª“ì–∞–Ω “õ...         kk   \n",
       "1                 –ê–ª–º–∞—Ç—ã –∞–∑–∞–º–∞—Ç—Ç–∞—Ä—ã –∂–∞—Ä–∞–π—Å—ã“£–¥–∞—Ä –∞–ª“ì–∞         kk   \n",
       "2                      “ö–∞–π—Ä–∞—Ç “ö“±–¥–∞–π–±–µ—Ä–≥–µ–Ω–æ–≤ —à—ã“õ—Ç—ã–º–∞?         kk   \n",
       "3  –°–∞–Ω–∂–∞—Ä –º–æ–ª–æ–¥–µ—Ü ,–ø–æ–π–º–∏—Ç–µ –æ–¥–∏–Ω –≤ –ø–æ–ª–µ –Ω–µ –≤–æ–∏–Ω ,“õ...         kk   \n",
       "4                                      ”ò–¥–µ–º—ñ —Ä–∏–∑–∞–º—ã–Ω         kk   \n",
       "\n",
       "   is_kazakh_model  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ / None / NaN / —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏\n",
    "df_clean = df[df[\"text_original\"].astype(str).str.strip().str.len() > 0].copy()\n",
    "\n",
    "# 2. –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "df_clean = df_clean.drop_duplicates(subset=[\"text_original\"]).reset_index(drop=True)\n",
    "\n",
    "# 3. –°—ç–º–ø–ª–∏—Ä—É–µ–º 3000 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç—Ä–æ–∫\n",
    "golden_df = df_clean.sample(3000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "golden_df.to_csv(\"golden_sample_3000.csv\", index=False)\n",
    "golden_df.to_json(\"golden_sample_3000.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "golden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5e9dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repr(api_key): 'REDACTED'\n",
      "len(api_key): 164\n",
      "‚úÖ –ö–ª—é—á –Ω–∞–π–¥–µ–Ω, –ø–µ—Ä–≤—ã–µ 12 —Å–∏–º–≤–æ–ª–æ–≤: sk-proj--pGX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –í–ê–ñ–ù–û: –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"repr(api_key):\", repr(api_key))\n",
    "print(\"len(api_key):\", len(api_key) if api_key is not None else None)\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "elif not api_key.startswith(\"sk-\"):\n",
    "    print(\"‚ùå –ö–ª—é—á –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'sk-'\")\n",
    "else:\n",
    "    print(\"‚úÖ –ö–ª—é—á –Ω–∞–π–¥–µ–Ω, –ø–µ—Ä–≤—ã–µ 12 —Å–∏–º–≤–æ–ª–æ–≤:\", api_key[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad40b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º .env\n",
    "load_dotenv()\n",
    "\n",
    "# –ß–∏—Ç–∞–µ–º –∫–ª—é—á\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "# === –ü–ê–†–ê–ú–ï–¢–†–´ ===\n",
    "INPUT_CSV = \"golden_sample_3000.csv\"       # –≤—Ö–æ–¥–Ω–æ–π –≥–æ–ª–¥–µ–Ω—Å–µ—Ç\n",
    "OUTPUT_JSONL = \"golden_annotated.jsonl\"    # –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ\n",
    "OUTPUT_CSV = \"golden_annotated.csv\"        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—á–∫–∞\n",
    "TEXT_COL = \"text_original\"                 # –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º\n",
    "MODEL_NAME = \"gpt-4.1-mini\"                # –∏–ª–∏ gpt-4.1, gpt-4o-mini –∏ —Ç.–ø.\n",
    "BATCH_SIZE = 30                            # —Å–∫–æ–ª—å–∫–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞ —Ä–∞–∑\n",
    "SLEEP_BETWEEN_CALLS = 0.5                  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞–¥–¥–æ—Å–∏—Ç—å API\n",
    "\n",
    "\n",
    "# === –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ ===\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "–°–µ–Ω “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ–≥—ñ –ø—ñ–∫—ñ—Ä–ª–µ—Ä–¥—ñ –º–æ–¥–µ—Ä–∞—Ü–∏—è–ª–∞–π—Ç—ã–Ω –∫”©–º–µ–∫—à—ñ—Å—ñ“£.\n",
    "–°–∞“ì–∞–Ω ”ô—Ä –ø—ñ–∫—ñ—Ä (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π) –º”ô—Ç—ñ–Ω—ñ –±–µ—Ä—ñ–ª–µ–¥—ñ. –°–µ–Ω—ñ“£ –º—ñ–Ω–¥–µ—Ç—ñ“£ ‚Äì –æ–Ω—ã —Ç–æ–∫—Å–∏–∫—Ç—ñ–ª—ñ–∫\n",
    "–±–æ–π—ã–Ω—à–∞ –∫–µ–ª–µ—Å—ñ –±–∏–Ω–∞—Ä–ª—ã“õ –±–µ–ª–≥—ñ–ª–µ—Ä–º–µ–Ω –±–µ–ª–≥—ñ–ª–µ—É (true/false).\n",
    "\n",
    "–ê–Ω—ã“õ—Ç–∞–º–∞–ª–∞—Ä:\n",
    "- is_toxic: –ü—ñ–∫—ñ—Ä–¥–µ –∫–µ–∑ –∫–µ–ª–≥–µ–Ω —Ç–æ–∫—Å–∏–∫—Ç—ñ–ª—ñ–∫ –±–∞—Ä –º–∞? –ï–≥–µ—Ä —Ç”©–º–µ–Ω–¥–µ–≥—ñ –∫–µ–∑ –∫–µ–ª–≥–µ–Ω\n",
    "  –∫–∞—Ç–µ–≥–æ—Ä–∏—è true –±–æ–ª—Å–∞, is_toxic = true.\n",
    "- toxic: –ñ–∞–ª–ø—ã –∞–≥—Ä–µ—Å—Å–∏–≤—Ç—ñ, “õ“±—Ä–º–µ—Ç—Å—ñ–∑, ”©—à–ø–µ–Ω–¥—ñ —Ä–µ“£–∫ (–º—ñ–Ω–¥–µ—Ç—Ç—ñ —Ç“Ø—Ä–¥–µ –±–∞–ª–∞“ì–∞—Ç —Å”©–∑\n",
    "  –±–æ–ª–º–∞—É—ã –º“Ø–º–∫—ñ–Ω).\n",
    "- obscene: –ë–∞–ª–∞“ì–∞—Ç/–±–æ“õ–∞—É—ã–∑ —Å”©–∑–¥–µ—Ä, ”©—Ç–µ –¥”©—Ä–µ–∫—ñ —Å–ª–µ–Ω–≥, ”ô–¥–µ–ø—Å—ñ–∑ —Å”©–∑–¥–µ—Ä.\n",
    "- threat: –ë–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –∞–¥–∞–º“ì–∞ –Ω–µ–º–µ—Å–µ –∞–¥–∞–º–¥–∞—Ä —Ç–æ–±—ã–Ω–∞ —Ñ–∏–∑–∏–∫–∞–ª—ã“õ –∑–∏—è–Ω –∫–µ–ª—Ç—ñ—Ä–µ–º—ñ–Ω\n",
    "  –¥–µ–ø “õ–æ—Ä“õ—ã—Ç—É (–º—ã—Å–∞–ª—ã, “±—Ä—ã–ø –∂—ñ–±–µ—Ä–µ–º—ñ–Ω, ”©–ª—Ç—ñ—Ä–µ–º—ñ–Ω –¥–µ–≥–µ–Ω —Å–∏—è“õ—Ç—ã).\n",
    "- insult: –ë–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –∞–¥–∞–º–¥—ã –Ω–µ–º–µ—Å–µ –∞–¥–∞–º–¥–∞—Ä–¥—ã “õ–æ—Ä–ª–∞—É, –∫–µ–º—Å—ñ—Ç—É (–∞“õ—ã–º–∞“õ, –º–∞–ª, —Ç.–±.).\n",
    "- hate: ”ò–ª–µ—É–º–µ—Ç—Ç—ñ–∫ —Ç–æ–ø“õ–∞ (“±–ª—Ç, –Ω”ô—Å—ñ–ª, –¥—ñ–Ω, –∂—ã–Ω—ã—Å, –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è, —Ç.–±.) –±–∞“ì—ã—Ç—Ç–∞–ª“ì–∞–Ω\n",
    "  ”©—à–ø–µ–Ω–¥—ñ–ª—ñ–∫, –∫–µ–º—Å—ñ—Ç—É, –∞–¥–∞–º —Ä–µ—Ç—ñ–Ω–¥–µ “õ“±“õ—ã“ì—ã–Ω –∂–æ“õ“õ–∞ —à—ã“ì–∞—Ä—É.\n",
    "\n",
    "”ò—Ä –ø—ñ–∫—ñ—Ä “Ø—à—ñ–Ω:\n",
    "- ”ò—Ä –±–µ–ª–≥—ñ–≥–µ true/false –±–µ—Ä,\n",
    "- “ö—ã—Å“õ–∞ explanation (2‚Äì3 —Å”©–π–ª–µ–º–Ω–µ–Ω –∞—Å–ø–∞—Å—ã–Ω) –∂–∞–∑—ã–ø –±–µ—Ä: –Ω–µ–≥–µ –¥”ô–ª –æ—Å—ã–ª–∞–π\n",
    "  –±–µ–ª–≥—ñ–ª–µ–≥–µ–Ω—ñ“£–¥—ñ —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä. –ï–≥–µ—Ä –ø—ñ–∫—ñ—Ä –±–µ–π—Ç–∞—Ä–∞–ø (—Ç–æ–∫—Å–∏–∫—Ç—ñ –µ–º–µ—Å) –±–æ–ª—Å–∞,\n",
    "  –æ–Ω—ã –¥–∞ –∂–∞–∑—ã–ø –∂—ñ–±–µ—Ä (–º—ã—Å–∞–ª—ã, \"–±–µ–π—Ç–∞—Ä–∞–ø –ø—ñ–∫—ñ—Ä, –∞–≥—Ä–µ—Å—Å–∏—è –∂–æ“õ\" –¥–µ–≥–µ–Ω —Å–∏—è“õ—Ç—ã).\n",
    "\n",
    "–ú–ê“¢–´–ó–î–´:\n",
    "- –¢–µ–∫ JSON “õ–∞–π—Ç–∞—Ä. –ë–∞—Å“õ–∞ –µ—à“õ–∞–Ω–¥–∞–π –º”ô—Ç—ñ–Ω –∂–∞–∑–±–∞.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_user_prompt(items: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    items: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤–∏–¥–∞ {\"id\": ..., \"text\": ...}\n",
    "    –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏.\n",
    "    \"\"\"\n",
    "    lines = [\n",
    "        \"–¢”©–º–µ–Ω–¥–µ –±—ñ—Ä–Ω–µ—à–µ –ø—ñ–∫—ñ—Ä –±–µ—Ä—ñ–ª–≥–µ–Ω. ”ò—Ä –ø—ñ–∫—ñ—Ä “Ø—à—ñ–Ω —Ç”©–º–µ–Ω–¥–µ–≥—ñ JSON —Ñ–æ—Ä–º–∞—Ç—ã–Ω–¥–∞ –∂–∞—É–∞–ø –±–µ—Ä:\",\n",
    "        \"\",\n",
    "        \"{\",\n",
    "        '  \"items\": [',\n",
    "        '    {',\n",
    "        '      \"id\": \"<id>\",',\n",
    "        '      \"is_toxic\": true/false,',\n",
    "        '      \"toxic\": true/false,',\n",
    "        '      \"obscene\": true/false,',\n",
    "        '      \"threat\": true/false,',\n",
    "        '      \"insult\": true/false,',\n",
    "        '      \"hate\": true/false,',\n",
    "        '      \"explanation\": \"<“õ—ã—Å“õ–∞ —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä–º–µ>\"',\n",
    "        '    },',\n",
    "        '    ...',\n",
    "        '  ]',\n",
    "        \"}\",\n",
    "        \"\",\n",
    "        \"–ü—ñ–∫—ñ—Ä–ª–µ—Ä —Ç—ñ–∑—ñ–º—ñ:\"\n",
    "    ]\n",
    "    for it in items:\n",
    "        lines.append(f'ID: {it[\"id\"]}')\n",
    "        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π\n",
    "        text_clean = str(it[\"text\"]).replace(\"\\n\", \" \").strip()\n",
    "        lines.append(f'Text: {text_clean}')\n",
    "        lines.append(\"---\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def annotate_batch(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    –î–µ–ª–∞–µ—Ç –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ OpenAI –¥–ª—è –±–∞—Ç—á–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤\n",
    "    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –ø–æ –∫–∞–∂–¥–æ–º—É id.\n",
    "    \"\"\"\n",
    "    user_prompt = build_user_prompt(items)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    # –ü–∞—Ä—Å–∏–º JSON\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–¥—Ä—É–≥ –≤–µ—Ä–Ω—É–ª–∞ –º—É—Å–æ—Ä ‚Äî –º–æ–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∏/–∏–ª–∏ —Ä–µ—Ç—Ä–∞–∏—Ç—å\n",
    "        raise RuntimeError(f\"JSON parsing error. Raw content:\\n{content}\")\n",
    "\n",
    "    if \"items\" not in data or not isinstance(data[\"items\"], list):\n",
    "        raise RuntimeError(f\"Unexpected JSON structure: {data}\")\n",
    "\n",
    "    return data[\"items\"]\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "    # –ì–æ—Ç–æ–≤–∏–º —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n",
    "    records = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[TEXT_COL]\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            continue\n",
    "        records.append({\n",
    "            \"id\": int(idx),   # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ row[\"id\"], –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å —è–≤–Ω—ã–π id\n",
    "            \"text\": text.strip(),\n",
    "        })\n",
    "\n",
    "    print(f\"–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏: {len(records)}\")\n",
    "\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ –±–∞—Ç—á–∞–º –∏ –ø–∏—à–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSONL\n",
    "    annotated = []\n",
    "    with open(OUTPUT_JSONL, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for i in range(0, len(records), BATCH_SIZE):\n",
    "            batch = records[i:i + BATCH_SIZE]\n",
    "            print(f\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {i}‚Äì{i+len(batch)-1}...\")\n",
    "\n",
    "            try:\n",
    "                batch_labels = annotate_batch(batch)\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –±–∞—Ç—á–∞ {i}: {e}\")\n",
    "                # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ä–µ—Ç—Ä–∞–π, –ø–∞—É–∑—É –∏ —Ç.–¥.\n",
    "                continue\n",
    "\n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSONL –ø–æ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ\n",
    "            for item in batch_labels:\n",
    "                f_out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "                annotated.append(item)\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    print(f\"–í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ: {len(annotated)}\")\n",
    "\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å—ë –≤ DataFrame –∏ –º—ë—Ä–¥–∂–∏–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º golden_df\n",
    "    ann_df = pd.DataFrame(annotated)\n",
    "\n",
    "    # –ü—Ä–∏–≤–æ–¥–∏–º –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è –∫ bool\n",
    "    bool_cols = [\"is_toxic\", \"toxic\", \"obscene\", \"threat\", \"insult\", \"hate\"]\n",
    "    for col in bool_cols:\n",
    "        if col in ann_df.columns:\n",
    "            ann_df[col] = ann_df[col].astype(bool)\n",
    "\n",
    "    # –°–æ–µ–¥–∏–Ω—è–µ–º –ø–æ id\n",
    "    df_golden = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "    merged = df_golden.merge(ann_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "    merged.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–¥–µ–Ω—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {OUTPUT_CSV}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d88058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏: 3000\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 0‚Äì29...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 30‚Äì59...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 60‚Äì89...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 90‚Äì119...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 120‚Äì149...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 150‚Äì179...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 180‚Äì209...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 210‚Äì239...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 240‚Äì269...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 270‚Äì299...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 300‚Äì329...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 330‚Äì359...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 360‚Äì389...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 390‚Äì419...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 420‚Äì449...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 450‚Äì479...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 480‚Äì509...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 510‚Äì539...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 540‚Äì569...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 570‚Äì599...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 600‚Äì629...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 630‚Äì659...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 660‚Äì689...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 690‚Äì719...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 720‚Äì749...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 750‚Äì779...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 780‚Äì809...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 810‚Äì839...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 840‚Äì869...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 870‚Äì899...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 900‚Äì929...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 930‚Äì959...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 960‚Äì989...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 990‚Äì1019...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1020‚Äì1049...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1050‚Äì1079...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1080‚Äì1109...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1110‚Äì1139...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1140‚Äì1169...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1170‚Äì1199...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1200‚Äì1229...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1230‚Äì1259...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1260‚Äì1289...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1290‚Äì1319...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1320‚Äì1349...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1350‚Äì1379...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1380‚Äì1409...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1410‚Äì1439...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1440‚Äì1469...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1470‚Äì1499...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1500‚Äì1529...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1530‚Äì1559...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1560‚Äì1589...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1590‚Äì1619...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1620‚Äì1649...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1650‚Äì1679...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1680‚Äì1709...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1710‚Äì1739...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1740‚Äì1769...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1770‚Äì1799...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1800‚Äì1829...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1830‚Äì1859...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1860‚Äì1889...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1890‚Äì1919...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1920‚Äì1949...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1950‚Äì1979...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 1980‚Äì2009...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2010‚Äì2039...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2040‚Äì2069...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2070‚Äì2099...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2100‚Äì2129...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2130‚Äì2159...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2160‚Äì2189...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2190‚Äì2219...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2220‚Äì2249...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2250‚Äì2279...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2280‚Äì2309...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2310‚Äì2339...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2340‚Äì2369...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2370‚Äì2399...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2400‚Äì2429...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2430‚Äì2459...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2460‚Äì2489...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2490‚Äì2519...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2520‚Äì2549...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2550‚Äì2579...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2580‚Äì2609...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2610‚Äì2639...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2640‚Äì2669...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2670‚Äì2699...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2700‚Äì2729...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2730‚Äì2759...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2760‚Äì2789...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2790‚Äì2819...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2820‚Äì2849...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2850‚Äì2879...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2880‚Äì2909...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2910‚Äì2939...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2940‚Äì2969...\n",
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á 2970‚Äì2999...\n",
      "–í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ: 3005\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns for key 'id'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# –°–æ–µ–¥–∏–Ω—è–µ–º –ø–æ id\u001b[39;00m\n\u001b[32m    176\u001b[39m df_golden = df.reset_index().rename(columns={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m merged = \u001b[43mdf_golden\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m merged.to_csv(OUTPUT_CSV, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–¥–µ–Ω—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10859\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10840\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10841\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10842\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10855\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m ) -> DataFrame:\n\u001b[32m  10857\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10860\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10868\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10869\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10873\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_tolerance(\u001b[38;5;28mself\u001b[39m.left_join_keys)\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:1509\u001b[39m, in \u001b[36m_MergeOperation._maybe_coerce_merge_keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[32m   1504\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1505\u001b[39m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1506\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1507\u001b[39m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1508\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1511\u001b[39m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[32m   1512\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk.dtype):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to merge on int64 and object columns for key 'id'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de0daa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3005 3004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π golden set\n",
    "df_golden = pd.read_csv(\"golden_sample_3000.csv\")\n",
    "df_golden = df_golden.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π (–µ—Å–ª–∏ —Ç—ã –∏—Ö —Å–æ—Ö—Ä–∞–Ω—è–ª –≤ JSONL –ø–æ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ)\n",
    "ann_df = pd.read_json(\"golden_annotated.jsonl\", lines=True)\n",
    "\n",
    "# 3. –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã id –∫ —Å—Ç—Ä–æ–∫–µ —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω\n",
    "df_golden[\"id\"] = df_golden[\"id\"].astype(str)\n",
    "ann_df[\"id\"] = ann_df[\"id\"].astype(str)\n",
    "\n",
    "# 4. –ú—ë—Ä–¥–∂–∏–º\n",
    "merged = df_golden.merge(ann_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "print(len(df_golden), len(ann_df), len(merged))\n",
    "merged.to_csv(\"golden_annotated_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac159eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6565386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccbb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged = pd.read_csv(\"golden_annotated_merged.csv\")\n",
    "df = pd.read_csv('kaz_df.csv')\n",
    "df = df[~df.comment_id.isin(merged.comment_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ab4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_KZ_CHECKPOINT = \"./kaz_roberta_toxic_kz\"  # <-- —Ç–≤–æ–π –ø—É—Ç—å\n",
    "\n",
    "tokenizer_kz = AutoTokenizer.from_pretrained(MODEL_KZ_CHECKPOINT)\n",
    "model_kz = AutoModelForSequenceClassification.from_pretrained(MODEL_KZ_CHECKPOINT)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_kz.to(device)\n",
    "model_kz.eval()\n",
    "\n",
    "# –ü–û–†–Ø–î–û–ö –õ–ï–ô–ë–õ–û–í –î–û–õ–ñ–ï–ù –°–û–í–ü–ê–î–ê–¢–¨ –° –¢–ï–ú, –ö–ê–ö –¢–´ –£–ß–ò–õ –ú–û–î–ï–õ–¨\n",
    "tox_aspect_names_kz = [\"toxic\", \"obscene\", \"threat\", \"insult\", \"hate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27ceccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity_batch_kz(texts, aggregate=False):\n",
    "    \"\"\"\n",
    "    texts: —Å–ø–∏—Å–æ–∫ —Å—ã—Ä—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (—Å—Ç—Ä–æ–∫–∏, NaN, —á–∏—Å–ª–∞ –∏ —Ç.–¥.)\n",
    "    aggregate=False -> –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É [batch, 5] –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º\n",
    "    aggregate=True  -> –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ score [batch]\n",
    "                      (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç —Ç–æ–∫—Å–∏—á–µ–Ω –ø–æ —Ö–æ—Ç—å –æ–¥–Ω–æ–º—É –∞—Å–ø–µ–∫—Ç—É)\n",
    "    \"\"\"\n",
    "    # —á–∏—Å—Ç–∏–º –≤—Ö–æ–¥: –≤—Å—ë –∫ —Å—Ç—Ä–æ–∫–µ, NaN/None -> \"\"\n",
    "    cleaned_texts = []\n",
    "    for t in texts:\n",
    "        if t is None or (isinstance(t, float) and pd.isna(t)):\n",
    "            cleaned_texts.append(\"\")\n",
    "        else:\n",
    "            cleaned_texts.append(str(t))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer_kz(\n",
    "            cleaned_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "\n",
    "        logits = model_kz(**inputs).logits\n",
    "        proba = torch.sigmoid(logits).cpu().numpy()  # shape: [batch, 5]\n",
    "\n",
    "    if aggregate:\n",
    "        # union probability: 1 - prod(1 - p_i) –ø–æ –≤—Å–µ–º 5 –∞—Å–ø–µ–∫—Ç–∞–º\n",
    "        agg = 1.0 - np.prod(1.0 - proba, axis=1)\n",
    "        return agg  # shape: [batch]\n",
    "\n",
    "    return proba  # shape: [batch, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b326cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity_batch_kz_compat(texts, aggregate=False):\n",
    "    \"\"\"\n",
    "    –°–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø–æ —Ñ–æ—Ä–º–µ –≤–∞—Ä–∏–∞–Ω—Ç:\n",
    "    aggregate=True -> 1 - p[:,0] * (1 - p[:,-1])\n",
    "    –ù–û: —É —Ç–µ–±—è p[:,0] = P(toxic), p[:,-1] = P(hate), —ç—Ç–æ –ù–ï —Ç–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ –≤ cointegrated.\n",
    "    \"\"\"\n",
    "    cleaned_texts = []\n",
    "    for t in texts:\n",
    "        if t is None or (isinstance(t, float) and pd.isna(t)):\n",
    "            cleaned_texts.append(\"\")\n",
    "        else:\n",
    "            cleaned_texts.append(str(t))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer_kz(\n",
    "            cleaned_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "\n",
    "        logits = model_kz(**inputs).logits\n",
    "        proba = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    if aggregate:\n",
    "        agg = 1.0 - proba[:, 0] * (1.0 - proba[:, -1])\n",
    "        return agg\n",
    "    return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32edc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_toxicity_to_df_kz(\n",
    "    df,\n",
    "    text_col=\"text_original\",\n",
    "    batch_size=64,\n",
    "    add_aspects=True,\n",
    "    use_compat_formula=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: DataFrame —Å —Ç–µ–∫—Å—Ç–∞–º–∏\n",
    "    text_col: –∫–æ–ª–æ–Ω–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º\n",
    "    batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "    add_aspects: –µ—Å–ª–∏ True ‚Äî —Å–æ–∑–¥–∞—Å—Ç –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º\n",
    "    use_compat_formula: –µ—Å–ª–∏ True ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—É—é —Ñ–æ—Ä–º—É–ª—É cointegrated\n",
    "                        (1 - p[:,0] * (1 - p[:,-1]));\n",
    "                        –µ—Å–ª–∏ False ‚Äî union probability –ø–æ –≤—Å–µ–º –∞—Å–ø–µ–∫—Ç–∞–º.\n",
    "    \"\"\"\n",
    "    all_agg_scores = []\n",
    "    all_aspects = []\n",
    "\n",
    "    fn = text2toxicity_batch_kz_compat if use_compat_formula else text2toxicity_batch_kz\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_texts = df[text_col].iloc[i:i + batch_size].tolist()\n",
    "\n",
    "        # –≤—Å–µ–≥–¥–∞ –±–µ—Ä—ë–º proba –∞—Å–ø–µ–∫—Ç–æ–≤:\n",
    "        batch_proba = text2toxicity_batch_kz(batch_texts, aggregate=False)  # [B, 5]\n",
    "\n",
    "        # –∞–≥—Ä–µ–≥–∞—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞\n",
    "        if use_compat_formula:\n",
    "            batch_agg = 1.0 - batch_proba[:, 0] * (1.0 - batch_proba[:, -1])\n",
    "        else:\n",
    "            batch_agg = 1.0 - np.prod(1.0 - batch_proba, axis=1)\n",
    "\n",
    "        all_agg_scores.extend(batch_agg.tolist())\n",
    "        all_aspects.append(batch_proba)\n",
    "\n",
    "    # –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score\n",
    "    df[\"toxicity_score_kz\"] = all_agg_scores\n",
    "\n",
    "    if add_aspects:\n",
    "        aspects_arr = np.vstack(all_aspects)  # [N, 5]\n",
    "        for j, name in enumerate(tox_aspect_names_kz):\n",
    "            df[f\"tox_kz_{name}\"] = aspects_arr[:, j]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd3a3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 510/510 [00:37<00:00, 13.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# df —É–∂–µ –µ—Å—Ç—å, —Ç–µ–∫—Å—Ç—ã –≤ \"text_original\"\n",
    "df = add_toxicity_to_df_kz(\n",
    "    df,\n",
    "    text_col=\"text_original\",\n",
    "    batch_size=64,\n",
    "    add_aspects=True,\n",
    "    use_compat_formula=False,  # —Ä–µ–∫–æ–º–µ–Ω–¥—É—é False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c950a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_original</th>\n",
       "      <th>lang_model</th>\n",
       "      <th>is_kazakh_model</th>\n",
       "      <th>toxicity_score_kz</th>\n",
       "      <th>tox_kz_toxic</th>\n",
       "      <th>tox_kz_obscene</th>\n",
       "      <th>tox_kz_threat</th>\n",
       "      <th>tox_kz_insult</th>\n",
       "      <th>tox_kz_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>UgwOqQmIvxrbJWlmTix4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä –±—Ä–∞—Ç–∞–Ω –ê–õ“í–ê! –ê–ª–ª–∞ –∂–∞—Ä –±–æ–ª—Å—ã–Ωü§≤</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061225</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.012781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21725</th>\n",
       "      <td>UgyyHiZi2Dqp1THeeIh4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä, –∞–π–Ω–∞–ª–∞–π—ã–Ω –∞–º–∞–Ω –±–æ–ª! –ï–ª–¥—ñ“£ –∞–∑–∞–º–∞—Ç—ã!‚ù§‚ù§‚ù§</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061323</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.012913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>UgwT5StIA5I7eJ-99MJ4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä –±–∞—É—ã—Ä—ã–º!!! –ñ”ô—Ä–∞–π—Å—ã“£!</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19068</th>\n",
       "      <td>UgwLl07xlGfBHrTwTxB4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä –±–∞—Ç—ã—Ä—ã–º –ë–∞“ì—ã“£ ”©—Å—Å—ñ–Ω –ê–π–Ω–∞–ª–∞–π—ã–Ω –ñ–∞—Ä–∞–π—Å—ã“£</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061406</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.013735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>UgxYTgN_ZoDWqraKeQB4AaABAg</td>\n",
       "      <td>–°–∞–Ω–∂–∞—Ä –∞–π–Ω–∞–ª–∞–π—ã–Ω –∞–±–∞–π –±–æ–ª—ã“£–¥–∞—Ä!</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.012240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29011</th>\n",
       "      <td>UgxwdQTTtvA9Y5q_ZyB4AaABAg</td>\n",
       "      <td>–û–ª–∞—Ä —á–∏–Ω–æ–≤–Ω–∏–∫ –µ–º–µ—Å —Ö–∞–ª—ã“õ “õ–∞—Ä–∞—É—à—ã–ª–∞—Ä “∞—Ä—ã–ª–∞—Ä. –¢–æ...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.964814</td>\n",
       "      <td>0.967543</td>\n",
       "      <td>0.973828</td>\n",
       "      <td>0.950625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>Ugy-UcT8wV1sce4m1Tl4AaABAg</td>\n",
       "      <td>–¢—ã“£–¥–∞ –º–µ–Ω—ñ, —à—ñ—Ä—ñ–∫ –±–∞—Å“õ–∞–Ω –ø–∞—Ä–∞“õ–æ—Ä—à—ã —à–µ–Ω–µ—É–Ω—ñ–∫,\\n...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.985325</td>\n",
       "      <td>0.910909</td>\n",
       "      <td>0.982862</td>\n",
       "      <td>0.930846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>Ugx1saTSIB1N_gMm_CV4AaABAg</td>\n",
       "      <td>“ö–∞–∑–∞“õ—Å—Ç–∞–Ω–Ω—ã“£ –∂–µ—Ä—ñ –∞–∑–¥–∞–π –æ—Å—ã–Ω—ã –∂–∞—Å–∞–ø –æ—Ç—ã—Ä“ì–∞–Ω–¥–∞—Ä...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.932082</td>\n",
       "      <td>0.840866</td>\n",
       "      <td>0.975859</td>\n",
       "      <td>0.992280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13862</th>\n",
       "      <td>UgyHeRGAFHxpRacK2Xd4AaABAg</td>\n",
       "      <td>–ë“±–ª –æ—Ä—ã—Å—Ç—ã“£ —à–æ—à“õ–∞–ª–∞—Ä—ã–Ω—ã“£ –±–∞—Ä–ª—ã“ì—ã–Ω “õ“±–ª–¥—ã“õ“õ–∞ —Å–∞–ª...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.935613</td>\n",
       "      <td>0.989941</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>0.939262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>UgyvruGD9O8olY66XlB4AaABAg</td>\n",
       "      <td>–ú—ã–Ω–∞ –æ—Ä—ã—Å—Ç—ã“£ –∞–π–Ω–∞–ª–∞—Å—ã–Ω–¥–∞ –∂“Ø—Ä–≥–µ–Ω–¥–µ—Ä —Ç“Ø–≥–µ–ª —Å–∞—Ç“õ—ã...</td>\n",
       "      <td>kk</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989255</td>\n",
       "      <td>0.983625</td>\n",
       "      <td>0.819481</td>\n",
       "      <td>0.986659</td>\n",
       "      <td>0.944652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32583 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comment_id  \\\n",
       "14821  UgwOqQmIvxrbJWlmTix4AaABAg   \n",
       "21725  UgyyHiZi2Dqp1THeeIh4AaABAg   \n",
       "11292  UgwT5StIA5I7eJ-99MJ4AaABAg   \n",
       "19068  UgwLl07xlGfBHrTwTxB4AaABAg   \n",
       "8268   UgxYTgN_ZoDWqraKeQB4AaABAg   \n",
       "...                           ...   \n",
       "29011  UgxwdQTTtvA9Y5q_ZyB4AaABAg   \n",
       "21583  Ugy-UcT8wV1sce4m1Tl4AaABAg   \n",
       "3980   Ugx1saTSIB1N_gMm_CV4AaABAg   \n",
       "13862  UgyHeRGAFHxpRacK2Xd4AaABAg   \n",
       "9137   UgyvruGD9O8olY66XlB4AaABAg   \n",
       "\n",
       "                                           text_original lang_model  \\\n",
       "14821               –°–∞–Ω–∂–∞—Ä –±—Ä–∞—Ç–∞–Ω –ê–õ“í–ê! –ê–ª–ª–∞ –∂–∞—Ä –±–æ–ª—Å—ã–Ωü§≤         kk   \n",
       "21725      –°–∞–Ω–∂–∞—Ä, –∞–π–Ω–∞–ª–∞–π—ã–Ω –∞–º–∞–Ω –±–æ–ª! –ï–ª–¥—ñ“£ –∞–∑–∞–º–∞—Ç—ã!‚ù§‚ù§‚ù§         kk   \n",
       "11292                        –°–∞–Ω–∂–∞—Ä –±–∞—É—ã—Ä—ã–º!!! –ñ”ô—Ä–∞–π—Å—ã“£!         kk   \n",
       "19068      –°–∞–Ω–∂–∞—Ä –±–∞—Ç—ã—Ä—ã–º –ë–∞“ì—ã“£ ”©—Å—Å—ñ–Ω –ê–π–Ω–∞–ª–∞–π—ã–Ω –ñ–∞—Ä–∞–π—Å—ã“£         kk   \n",
       "8268                     –°–∞–Ω–∂–∞—Ä –∞–π–Ω–∞–ª–∞–π—ã–Ω –∞–±–∞–π –±–æ–ª—ã“£–¥–∞—Ä!         kk   \n",
       "...                                                  ...        ...   \n",
       "29011  –û–ª–∞—Ä —á–∏–Ω–æ–≤–Ω–∏–∫ –µ–º–µ—Å —Ö–∞–ª—ã“õ “õ–∞—Ä–∞—É—à—ã–ª–∞—Ä “∞—Ä—ã–ª–∞—Ä. –¢–æ...         kk   \n",
       "21583  –¢—ã“£–¥–∞ –º–µ–Ω—ñ, —à—ñ—Ä—ñ–∫ –±–∞—Å“õ–∞–Ω –ø–∞—Ä–∞“õ–æ—Ä—à—ã —à–µ–Ω–µ—É–Ω—ñ–∫,\\n...         kk   \n",
       "3980   “ö–∞–∑–∞“õ—Å—Ç–∞–Ω–Ω—ã“£ –∂–µ—Ä—ñ –∞–∑–¥–∞–π –æ—Å—ã–Ω—ã –∂–∞—Å–∞–ø –æ—Ç—ã—Ä“ì–∞–Ω–¥–∞—Ä...         kk   \n",
       "13862  –ë“±–ª –æ—Ä—ã—Å—Ç—ã“£ —à–æ—à“õ–∞–ª–∞—Ä—ã–Ω—ã“£ –±–∞—Ä–ª—ã“ì—ã–Ω “õ“±–ª–¥—ã“õ“õ–∞ —Å–∞–ª...         kk   \n",
       "9137   –ú—ã–Ω–∞ –æ—Ä—ã—Å—Ç—ã“£ –∞–π–Ω–∞–ª–∞—Å—ã–Ω–¥–∞ –∂“Ø—Ä–≥–µ–Ω–¥–µ—Ä —Ç“Ø–≥–µ–ª —Å–∞—Ç“õ—ã...         kk   \n",
       "\n",
       "       is_kazakh_model  toxicity_score_kz  tox_kz_toxic  tox_kz_obscene  \\\n",
       "14821             True           0.061225      0.014646        0.011479   \n",
       "21725             True           0.061323      0.014796        0.011169   \n",
       "11292             True           0.061356      0.016182        0.010862   \n",
       "19068             True           0.061406      0.014325        0.011466   \n",
       "8268              True           0.061410      0.014855        0.011911   \n",
       "...                ...                ...           ...             ...   \n",
       "29011             True           1.000000      0.990221        0.964814   \n",
       "21583             True           1.000000      0.990070        0.985325   \n",
       "3980              True           1.000000      0.986003        0.932082   \n",
       "13862             True           1.000000      0.988682        0.935613   \n",
       "9137              True           1.000000      0.989255        0.983625   \n",
       "\n",
       "       tox_kz_threat  tox_kz_insult  tox_kz_hate  \n",
       "14821       0.013015       0.010856     0.012781  \n",
       "21725       0.011932       0.012069     0.012913  \n",
       "11292       0.011773       0.012127     0.011967  \n",
       "19068       0.012363       0.011079     0.013735  \n",
       "8268        0.011906       0.012063     0.012240  \n",
       "...              ...            ...          ...  \n",
       "29011       0.967543       0.973828     0.950625  \n",
       "21583       0.910909       0.982862     0.930846  \n",
       "3980        0.840866       0.975859     0.992280  \n",
       "13862       0.989941       0.942639     0.939262  \n",
       "9137        0.819481       0.986659     0.944652  \n",
       "\n",
       "[32583 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('toxicity_score_kz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
